# -*- coding: utf-8 -*-
"""HealthAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x_vYBc8QD9MAwWJST9s3SlSc88dRxY8x
"""

!pip install gradio transformers torch

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# Load model and tokenizer
model_name = "ibm-granite/granite-3.2-2b-instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto" if torch.cuda.is_available() else None
)

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

def generate_response(prompt, max_length=1024):
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)

    if torch.cuda.is_available():
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=max_length,
            temperature=0.7,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    response = response.replace(prompt, "").strip()
    return response

def disease_prediction(symptoms):
    prompt = f"Based on the following symptoms, provide possible medical conditions and general medication suggestions. Always emphasize the importance of consulting a doctor.\nSymptoms: {symptoms}"
    return generate_response(prompt, max_length=1200)

def treatment_plan(condition, age, gender, medical_history):
    prompt = f"Generate personalized treatment suggestions for the following patient information. Include home remedies and general medication guidelines.\nCondition: {condition}\nAge: {age}\nGender: {gender}\nMedical History: {medical_history}"
    return generate_response(prompt, max_length=1200)

# Create Gradio interface
with gr.Blocks() as app:
    gr.Markdown("## ðŸ©º Medical AI Assistant")
    gr.Markdown("*Disclaimer:* This is for informational purposes only. Always consult healthcare professionals for medical advice.")

    with gr.Tabs():
        with gr.TabItem("Disease Prediction"):
            with gr.Row():
                with gr.Column():
                    symptoms_input = gr.Textbox(
                        label="Enter Symptoms",
                        placeholder="e.g., fever, headache, cough, fatigue...",
                        lines=4
                    )
                    predict_btn = gr.Button("Analyze Symptoms")
                with gr.Column():
                    prediction_output = gr.Textbox(label="Possible Conditions & Recommendations", lines=20)

            predict_btn.click(disease_prediction, inputs=symptoms_input, outputs=prediction_output)

        with gr.TabItem("Treatment Plans"):
            with gr.Row():
                with gr.Column():
                    condition_input = gr.Textbox(label="Medical Condition")
                    age_input = gr.Number(label="Age")
                    gender_input = gr.Radio(["Male", "Female", "Other"], label="Gender")
                    medical_history_input = gr.Textbox(label="Medical History", lines=4)
                    treatment_btn = gr.Button("Get Treatment Plan")
                with gr.Column():
                    treatment_output = gr.Textbox(label="Treatment Suggestions", lines=20)

            treatment_btn.click(
                treatment_plan,
                inputs=[condition_input, age_input, gender_input, medical_history_input],
                outputs=treatment_output
            )

app.launch()

app.launch(share=True)